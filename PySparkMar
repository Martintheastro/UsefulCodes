**************** CODE APPLIED AFTER COPY PIPELINE TO ADD TIMESTAMP AND REPORTING OF LOADED ROWS***********************************************************************


from pyspark.sql.functions import *

# Change the name of tables if necessary: staging table is from pipeline, Silver table is adjusted table, Grouped table is table for teporting and only one for all tables:
TableNameStaging = ""
TableNameSilver = ""
TableNameGrouped = ""

# adding ExtractTimestampGMT to the dataframe with current timestamp and saving the table as silver table:
df=spark.read.table(TableNameStaging)\
    .withColumn('ExtractTimestampGMT',current_timestamp())\
    .write.mode("overwrite").format("delta").save(f"Tables/{TableNameSilver}")

# loading the silver table to gorup by timestamp and count number of rows and also adding name of the table as new column "TableName", renaming "count" column to NumOfRowsLoaded
# and reordering columns with 'selec' function and appending the dataframe as delta table to TableNameGrouped:
df = spark.read.table(TableNameSilver)\
    .groupBy("ExtractTimestampGMT")\
    .count()\
    .withColumn("TableName",lit(TableNameSilver))\
    .withColumnRenamed("count","NumOfRowsLoaded")\
    .select("ExtractTimestampGMT","TableName","NumOfRowsLoaded")

df.write.mode("append").format("delta").partitionBy("ExtractTimestampGMT").save(f"Tables/{TableNameGrouped}")
